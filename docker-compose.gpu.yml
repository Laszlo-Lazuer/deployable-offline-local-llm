version: '3.8'

# GPU-accelerated configuration for macOS Metal
# NOTE: Containers cannot access Metal GPU on macOS
# Solution: Use native Ollama (installed via brew) with GPU support
# Usage: ./start-gpu.sh

services:
  # The Redis message queue
  redis:
    image: redis:7-alpine
    container_name: redis

  # NOTE: Ollama service removed - using host Ollama with Metal GPU
  # Start native Ollama with: ollama serve
  # This provides 10-50x faster inference via Metal GPU

  # The Flask web app (cashier)
  web-app:
    build: .
    container_name: web-app
    ports:
      - "5001:5000"
    depends_on:
      - redis
    command: flask --app app run --host=0.0.0.0

  # The Celery worker (barista)
  # Connects to host Ollama for Metal GPU acceleration
  worker:
    build: .
    container_name: worker
    depends_on:
      - redis
    volumes:
      - ./data:/app/data
    # Allow access to host's Ollama service
    extra_hosts:
      - "host.docker.internal:host-gateway"
    command: celery -A worker.celery_app worker --loglevel=info --concurrency=1
