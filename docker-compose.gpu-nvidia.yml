version: '3.8'

services:
  redis:
    image: redis:alpine
    container_name: redis
    ports:
      - "6379:6379"
    networks:
      - llm-network

  # Use host's Ollama with NVIDIA GPU
  # NOTE: Ollama must be running on host with NVIDIA GPU support
  # Install: curl -fsSL https://ollama.com/install.sh | sh
  # Then ensure NVIDIA drivers and CUDA are installed

  web-app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: web-app
    ports:
      - "5001:5001"
    environment:
      - REDIS_URL=redis://redis:6379/0
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
      - DATA_DIR=/app/data
    volumes:
      - ./data:/app/data
      - ./cache:/app/cache
    depends_on:
      - redis
    networks:
      - llm-network
    extra_hosts:
      - "host.docker.internal:host-gateway"

  worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: worker
    command: celery -A worker worker --loglevel=info --concurrency=1
    environment:
      - REDIS_URL=redis://redis:6379/0
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
      - DATA_DIR=/app/data
    volumes:
      - ./data:/app/data
      - ./cache:/app/cache
    depends_on:
      - redis
    networks:
      - llm-network
    extra_hosts:
      - "host.docker.internal:host-gateway"

networks:
  llm-network:
    driver: bridge
